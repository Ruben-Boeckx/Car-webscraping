{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '€' (U+20AC) (2673700002.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 58\u001b[1;36m\u001b[0m\n\u001b[1;33m    €_index = all_text.find('€')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '€' (U+20AC)\n"
     ]
    }
   ],
   "source": [
    "class MercedesA150Scraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.autoscout24.be/nl/\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "    \n",
    "    def create_search_url(self, page=1):\n",
    "        \"\"\"Create search URL specifically for Mercedes A 150\"\"\"\n",
    "        url = (f\"{self.base_url}lst/mercedes-benz/a-klasse/\"\n",
    "               f\"?sort=standard&desc=0&cy=B&atype=C&ustate=N%2CU&powertype=kw\"\n",
    "               f\"&search_id=&filters=model-a_150&page={page}\")\n",
    "        return url\n",
    "    \n",
    "    def get_page_content(self, url):\n",
    "        \"\"\"Fetch page content with error handling and rate limiting\"\"\"\n",
    "        try:\n",
    "            time.sleep(randint(2, 5))\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Print status code and URL for debugging\n",
    "            print(f\"Status Code: {response.status_code}\")\n",
    "            print(f\"URL: {url}\")\n",
    "            \n",
    "            return response.text\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching page: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_price(self, listing):\n",
    "        \"\"\"Extract price with multiple selector attempts and debugging\"\"\"\n",
    "        try:\n",
    "            # Try multiple possible price selectors\n",
    "            price_selectors = [\n",
    "                'div[data-price]',  # Try data attribute\n",
    "                'span[data-price]',\n",
    "                'div.Price_price__XZDdY',\n",
    "                'span.Price_price__XZDdY',\n",
    "                '.PriceAndSeals_price__li8qU',  # New possible class\n",
    "                '.PriceContainer_price__iQHNs',  # Another possible class\n",
    "                '[class*=\"price\"]'  # Generic price class search\n",
    "            ]\n",
    "            \n",
    "            for selector in price_selectors:\n",
    "                price_element = listing.select_one(selector)\n",
    "                if price_element:\n",
    "                    # Try different attributes\n",
    "                    price = (price_element.get('data-price') or \n",
    "                            price_element.text.strip())\n",
    "                    if price:\n",
    "                        # Print found price for debugging\n",
    "                        print(f\"Found price: {price}\")\n",
    "                        return price\n",
    "            \n",
    "            # If no price found with selectors, try finding € symbol\n",
    "            all_text = listing.get_text()\n",
    "            €_index = all_text.find('€')\n",
    "            if €_index != -1:\n",
    "                # Extract price near € symbol\n",
    "                price_text = all_text[€_index:€_index+20]  # Take 20 chars after €\n",
    "                price_text = ''.join(c for c in price_text if c.isdigit() or c in '€,.')\n",
    "                if price_text:\n",
    "                    return price_text\n",
    "            \n",
    "            return 'N/A'\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting price: {e}\")\n",
    "            return 'N/A'\n",
    "    \n",
    "    def parse_listing(self, listing):\n",
    "        \"\"\"Extract detailed information from a single A 150 listing\"\"\"\n",
    "        try:\n",
    "            # Debug print\n",
    "            print(\"\\nParsing new listing...\")\n",
    "            \n",
    "            # Basic information\n",
    "            title = listing.find('h2', class_='ListItem_title__znV2I')\n",
    "            title = title.text.strip() if title else 'N/A'\n",
    "            print(f\"Found title: {title}\")\n",
    "            \n",
    "            # Extract price using the new method\n",
    "            price = self.extract_price(listing)\n",
    "            print(f\"Extracted price: {price}\")\n",
    "            \n",
    "            # Initialize details dictionary\n",
    "            details_dict = {\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'mileage': 'N/A',\n",
    "                'year': 'N/A',\n",
    "                'transmission': 'N/A',\n",
    "                'fuel_type': 'N/A',\n",
    "                'power_kw': 'N/A',\n",
    "                'seller_location': 'N/A',\n",
    "                'listing_url': 'N/A',\n",
    "                'scrape_date': datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            }\n",
    "            \n",
    "            # Extract URL\n",
    "            url_element = listing.find('a', class_='ListItem_title__znV2I')\n",
    "            if url_element and 'href' in url_element.attrs:\n",
    "                details_dict['listing_url'] = 'https://www.autoscout24.be' + url_element['href']\n",
    "            \n",
    "            # Extract details from the specification table\n",
    "            details = listing.find_all('span', class_='VehicleDetailTable_item__koEV4')\n",
    "            \n",
    "            for detail in details:\n",
    "                detail_text = detail.text.strip()\n",
    "                \n",
    "                if 'km' in detail_text.lower():\n",
    "                    details_dict['mileage'] = detail_text\n",
    "                elif len(detail_text) == 4 and detail_text.isdigit():\n",
    "                    details_dict['year'] = detail_text\n",
    "                elif 'kw' in detail_text.lower() or 'pk' in detail_text.lower():\n",
    "                    details_dict['power_kw'] = detail_text\n",
    "                elif any(fuel in detail_text.lower() for fuel in ['benzine', 'diesel', 'hybride']):\n",
    "                    details_dict['fuel_type'] = detail_text\n",
    "                elif any(trans in detail_text.lower() for trans in ['automatisch', 'handgeschakeld']):\n",
    "                    details_dict['transmission'] = detail_text\n",
    "            \n",
    "            # Extract seller location\n",
    "            location = listing.find('span', class_='ListItem_location__K_a5t')\n",
    "            if location:\n",
    "                details_dict['seller_location'] = location.text.strip()\n",
    "            \n",
    "            return details_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing listing: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def clean_price(self, price):\n",
    "        \"\"\"Clean price string to numeric value\"\"\"\n",
    "        try:\n",
    "            if price == 'N/A':\n",
    "                return None\n",
    "            # Remove € symbol and any thousand separators\n",
    "            price = str(price).replace('€', '').replace('.', '').replace(',', '').strip()\n",
    "            # Extract only digits\n",
    "            price = ''.join(filter(str.isdigit, price))\n",
    "            return float(price) if price else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning price {price}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_listings(self, max_pages=5):\n",
    "        \"\"\"Scrape multiple pages of A 150 listings\"\"\"\n",
    "        all_listings = []\n",
    "        total_listings = 0\n",
    "        \n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"\\nScraping page {page}...\")\n",
    "            url = self.create_search_url(page)\n",
    "            content = self.get_page_content(url)\n",
    "            \n",
    "            if not content:\n",
    "                continue\n",
    "            \n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            listings = soup.find_all('article', class_='ListItem_article__qgyo_')\n",
    "            \n",
    "            print(f\"Found {len(listings)} listings on page {page}\")\n",
    "            \n",
    "            if not listings:\n",
    "                print(f\"No more listings found on page {page}\")\n",
    "                break\n",
    "            \n",
    "            for listing in listings:\n",
    "                listing_data = self.parse_listing(listing)\n",
    "                if listing_data:\n",
    "                    if 'a 150' in listing_data['title'].lower():\n",
    "                        all_listings.append(listing_data)\n",
    "                        total_listings += 1\n",
    "            \n",
    "            print(f\"Scraped page {page}, found {len(listings)} listings, {total_listings} total A 150s\")\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(all_listings)\n",
    "        \n",
    "        # Clean price column\n",
    "        df['price'] = df['price'].apply(self.clean_price)\n",
    "        \n",
    "        # Clean mileage column\n",
    "        df['mileage'] = df['mileage'].str.replace('km', '').str.replace('.', '').str.strip()\n",
    "        df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce')\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = MercedesA150Scraper()\n",
    "    results = scraper.scrape_listings()\n",
    "    \n",
    "    # Save results to CSV with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'mercedes_a150_listings_{timestamp}.csv'\n",
    "    results.to_csv(filename, index=False)\n",
    "    \n",
    "    # Print some basic statistics\n",
    "    print(\"\\nScraping Summary:\")\n",
    "    print(f\"Total listings found: {len(results)}\")\n",
    "    if len(results) > 0:\n",
    "        print(f\"\\nPrice Statistics:\")\n",
    "        print(results['price'].describe())\n",
    "        print(f\"\\nMileage Statistics:\")\n",
    "        print(results['mileage'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
